{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid 19 Cases PredictionAssignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks include:\n",
    "#### 1. Develop an LSTM model to predict COVID cases in Malaysia.\n",
    "#### 2. Ensure MAPE error is less than 1% on the testing dataset.\n",
    "#### 3. Display training loss using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Setup\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "from  keras import callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from windowing import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Load train data as Dataframe\n",
    "df_cases_train_malaysia = pd.read_csv('2024_COVID_TRAIN_SET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load train data as Dataframe\n",
    "df_cases_train_malaysia_test = pd.read_csv('2024_COVID_TEST_SET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_train_malaysia = pd.concat([df_cases_train_malaysia, df_cases_train_malaysia_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_train_malaysia.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_train_malaysia.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_train_malaysia.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAN with 0\n",
    "df_cases_train_malaysia.fillna(0, inplace=True)\n",
    "df_cases_train_malaysia_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_train_malaysia.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contain the time steps into seperate_variables\n",
    "date_time = pd.to_datetime(df_cases_train_malaysia.pop('date'), format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation\n",
    "plt.rcParams['figure.figsize'] = (12, 3 * 9)\n",
    "\n",
    "plot_cols = ['cases_new', 'cases_import', 'cases_recovered', 'cases_active',\n",
    "       'cases_cluster', 'cases_unvax', 'cases_pvax', 'cases_fvax',\n",
    "       'cases_boost', 'cluster_import','cluster_religious', 'cluster_community', 'cluster_highRisk',\n",
    "       'cluster_education', 'cluster_detentionCentre', 'cluster_workplace']\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 3 * len(plot_cols))\n",
    "\n",
    "plot_features = df_cases_train_malaysia[plot_cols]\n",
    "plot_features.index = date_time\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Develop LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Splitting (70%, 20%, 10%) split for the training, validation, and test sets\n",
    "column_indices = {name: i for i, name in enumerate(df_cases_train_malaysia.columns)}\n",
    "\n",
    "n = len(df_cases_train_malaysia)\n",
    "train_df = df_cases_train_malaysia[0:int(n*0.7)]\n",
    "val_df = df_cases_train_malaysia_test[int(n*0.7):int(n*0.9)]\n",
    "test_df = df_cases_train_malaysia[int(n*0.9):]\n",
    "\n",
    "num_features = df_cases_train_malaysia.shape[1]\n",
    "\n",
    "cl = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Normalizing Standardscaler\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_dfnn = (train_df - train_mean) / train_std\n",
    "val_dfnn = (val_df - train_mean) / train_std\n",
    "test_dfnn = (test_df - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_dfss = scaler.fit_transform(train_df)\n",
    "train_dfss = pd.DataFrame(train_dfss, columns=cl)\n",
    "\n",
    "val_dfss = scaler.fit_transform(val_df)\n",
    "val_dfss = pd.DataFrame(val_dfss,columns=cl)\n",
    "\n",
    "test_dfss = scaler.fit_transform(test_df)\n",
    "test_dfss = pd.DataFrame(test_dfss,columns=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normilizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "n = Normalizer()\n",
    "train_dfn = n.fit_transform(train_df)\n",
    "train_dfn = pd.DataFrame(train_dfn, columns=cl)\n",
    "\n",
    "val_dfn = n.fit_transform(val_df)\n",
    "val_dfn = pd.DataFrame(val_dfn,columns=cl)\n",
    "\n",
    "test_dfn = n.fit_transform(test_df)\n",
    "test_dfn = pd.DataFrame(test_dfn,columns=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "train_dfmm = minmax.fit_transform(train_df)\n",
    "train_dfmm = pd.DataFrame(train_dfmm, columns=cl)\n",
    "\n",
    "val_dfmm = minmax.fit_transform(val_df)\n",
    "val_dfmm = pd.DataFrame(val_dfmm,columns=cl)\n",
    "\n",
    "test_dfmm = minmax.fit_transform(test_df)\n",
    "test_dfmm = pd.DataFrame(test_dfmm,columns=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Robust Scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rs = RobustScaler()\n",
    "train_dfrs = rs.fit_transform(train_df)\n",
    "train_dfrs = pd.DataFrame(train_dfrs, columns=cl)\n",
    "\n",
    "val_dfrs = rs.fit_transform(val_df)\n",
    "val_dfrs = pd.DataFrame(val_dfrs,columns=cl)\n",
    "\n",
    "test_dfrs = rs.fit_transform(test_df)\n",
    "test_dfrs = pd.DataFrame(test_dfrs,columns=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfnn.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfnn.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single step\n",
    "wide_window = WindowGenerator(input_width=30,label_width=30,shift=1,train_df=train_dfnn, val_df=val_dfnn, test_df=test_dfnn,label_columns=['cases_new'])\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window.plot(plot_col='cases_new',max_subplots=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath for checkpoint and tensorboard\n",
    "filepath = os.getcwd()\n",
    "\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint Path\n",
    "checkpoint_filepath = r\"c:\\Users\\USER\\Downloads\\AI_SHRDC\\Capstone1\\chechpoint.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard Path\n",
    "logpath = os.path.join(filepath,'tensorboard_log',datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "tb = callbacks.TensorBoard(logpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Regularizer\n",
    "regularization_strength = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM single \n",
    "lstm_single_step = tf.keras.models.Sequential()\n",
    "\n",
    "lstm_single_step.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "\n",
    "lstm_single_step.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windowing import compile_and_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "history_single_step = compile_and_fit(lstm_single_step,wide_window,checkpoint_filepath,tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Between Loss and Val Loss\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(history_single_step.history['loss'],color='teal',label='loss')\n",
    "plt.plot(history_single_step.history['val_loss'],color='orange',label='val_loss')\n",
    "fig.suptitle('Loss',fontsize=10)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Absolute Percentage\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.plot(history_single_step.history['mean_absolute_percentage_error'],color='teal',label='loss')\n",
    "plt.plot(history_single_step.history['val_mean_absolute_percentage_error'],color='orange',label='val_loss')\n",
    "fig.suptitle('Loss',fontsize=10)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_single_step.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result \n",
    "wide_window.plot(plot_col='cases_new',model=lstm_single_step,max_subplots=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutlistep Model\n",
    "OUT_STEPS = 30\n",
    "mutli_window = WindowGenerator(input_width=30,label_width=OUT_STEPS,shift=OUT_STEPS,train_df=train_dfnn, val_df=val_dfnn, test_df=test_dfnn,label_columns=['cases_new'])\n",
    "mutli_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint Path\n",
    "checkpoint_filepath_m = r\"c:\\Users\\USER\\Downloads\\AI_SHRDC\\Capstone1\\chechpoint-mutli.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard Path\n",
    "logpath = os.path.join(filepath,'tensorboard_log_m',datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "tb_m = callbacks.TensorBoard(logpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutli_window.plot(plot_col='cases_new',max_subplots=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM mutli \n",
    "lstm_mutli_step = tf.keras.Sequential()\n",
    "\n",
    "lstm_mutli_step.add(tf.keras.layers.LSTM(32,return_sequences=False))\n",
    "\n",
    "lstm_mutli_step.add(tf.keras.layers.Dense(OUT_STEPS*num_features))\n",
    "\n",
    "lstm_mutli_step.add(tf.keras.layers.Reshape([OUT_STEPS,num_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mutli_step = compile_and_fit(lstm_mutli_step,mutli_window,checkpoint_filepath_m,tb_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutli_window.plot(plot_col='cases_new',model=lstm_mutli_step,max_subplots=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI07_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
